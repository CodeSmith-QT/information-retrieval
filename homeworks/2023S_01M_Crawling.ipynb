{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c036ac2f-45f2-4cbf-918c-4e62c51ce1c5",
      "metadata": {
        "id": "c036ac2f-45f2-4cbf-918c-4e62c51ce1c5"
      },
      "source": [
        "# NB: This document contains master-level tasks\n",
        "\n",
        "## 1. [M][15] Account the caching policy\n",
        "\n",
        "Sometimes remote documents (especially when we speak about static content like `js` or `gif`) can swear that they will not change for some time. This is done by setting [Cache-Control response header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cc23fb17-ef00-4a68-a28e-870bf586d6f0",
      "metadata": {
        "id": "cc23fb17-ef00-4a68-a28e-870bf586d6f0"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "response = requests.head('https://polyfill.io/v3/polyfill.min.js')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "def process_cache(cache, fetch_date):  \n",
        "  \"\"\"\n",
        "    Function for checking cache expiry\n",
        "    args:\n",
        "      cache: The cache-control string returned by the response\n",
        "      fetch_date: The date the response was gotten\n",
        "    response: \n",
        "      returns false if\n",
        "        1. no cache-control header\n",
        "        2. the cache-control header contains either no-store or no-cache\n",
        "        3. the date has expired\n",
        "      otherwise returns true\n",
        "  \"\"\"\n",
        "  if cache is None:\n",
        "    print('No Cache Header')\n",
        "    return False\n",
        "  cache_arr = list(map(str.strip, cache.split(',')))\n",
        "  if 'no-store' in cache_arr or 'no-cache' in cache_arr:\n",
        "    print('Cache has no-store or no-cache field')\n",
        "    return False\n",
        "  if 'public' in  cache_arr:\n",
        "    print('Cache-header has public')\n",
        "    re_s_max_age = re.compile('^s-maxage.*')\n",
        "    s_max_age_list = list(filter(re_s_max_age.match, cache_arr))\n",
        "    if len(s_max_age_list) > 0:\n",
        "      s_max_age = s_max_age_list[0].split('=')[1]\n",
        "      dt = datetime.datetime.strptime(fetch_date, '%a, %d %b %Y %H:%M:%S GMT')\n",
        "      expired_time = dt + datetime.timedelta(seconds=int(s_max_age))            \n",
        "      if datetime.datetime.now() < expired_time:\n",
        "        print(\"Cache hasn't expired \")\n",
        "        return True\n",
        "    else:\n",
        "      re_max_age = re.compile('^max-age.*')\n",
        "      max_age_list = list(filter(re_max_age.match, cache_arr))\n",
        "      if len(max_age_list) > 0:\n",
        "        max_age = max_age_list[0].split('=')[1]\n",
        "        dt = datetime.datetime.strptime(fetch_date, '%a, %d %b %Y %H:%M:%S GMT')\n",
        "        expired_time = dt + datetime.timedelta(seconds=int(max_age))\n",
        "        if datetime.datetime.now() < expired_time:\n",
        "          print(\"Cache hasn't expired \")\n",
        "          return True\n",
        "    return False\n",
        "  elif 'private' in cache_arr:\n",
        "      print('Cache-header has private')\n",
        "      re_max_age = re.compile('^max-age.*')\n",
        "      max_age_list = list(filter(re_max_age.match, cache_arr))\n",
        "      if len(max_age_list) > 0:\n",
        "        max_age = max_age_list[0].split('=')[1]\n",
        "        dt = datetime.datetime.strptime(fetch_date, '%a, %d %b %Y %H:%M:%S GMT')\n",
        "        expired_time = dt + datetime.timedelta(seconds=int(max_age))\n",
        "        if datetime.datetime.now() < expired_time:\n",
        "          print(\"Cache hasn't expired \")\n",
        "          return True\n",
        "  print(\"Cache has expired\")\n",
        "  return False"
      ],
      "metadata": {
        "id": "QRum4kELkceG"
      },
      "id": "QRum4kELkceG",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "\n",
        "\n",
        "def wget(url):\n",
        "    \"\"\"\n",
        "      Function for requesting urls\n",
        "      args:\n",
        "        The URL to be requested\n",
        "      response:\n",
        "        The content of the response\n",
        "    \"\"\"\n",
        "    def handleLoadToVar(resp):\n",
        "      \"\"\"\n",
        "        Function for chunking the http response in order to manage system resources\n",
        "        args:\n",
        "          resp: The http response\n",
        "        response:\n",
        "          The chunked response\n",
        "      \"\"\"\n",
        "      result = bytearray()\n",
        "      resp.raise_for_status()      \n",
        "      for chunk in resp.iter_content(chunk_size=8192): \n",
        "        result += chunk\n",
        "      return result\n",
        "    \n",
        "    # allow redirects - in case file is relocated\n",
        "    resp = requests.get(url, allow_redirects=True, stream = True)\n",
        "    # this can also be 2xx, but for simplicity now we stick to 200\n",
        "    # you can also check for `resp.ok`\n",
        "    if resp.status_code != 200:\n",
        "        print(resp.status_code, resp.reason, 'for', url)\n",
        "        return\n",
        "    \n",
        "    # just to be cool and print something\n",
        "    print(*[f\"{key}: {value}\" for key, value in resp.headers.items()], sep='\\n')\n",
        "    print()\n",
        "    \n",
        "    return handleLoadToVar(resp)"
      ],
      "metadata": {
        "id": "iJOOdPpckP42"
      },
      "id": "iJOOdPpckP42",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wget_cache(url):\n",
        "  \"\"\"\n",
        "      Function for requesting urls\n",
        "      args:\n",
        "        The URL to be requested\n",
        "      response: \n",
        "        A tuple containing the content of the response, the cache-control header and the date header\n",
        "    \"\"\"\n",
        "  resp = requests.get(url, allow_redirects=True, stream = True)   \n",
        "  def handleLoadToVar(resp):\n",
        "      result = bytearray()\n",
        "      resp.raise_for_status()      \n",
        "      for chunk in resp.iter_content(chunk_size=8192):           \n",
        "        result += chunk\n",
        "      return result\n",
        "  print(\"Fetching file from online\") \n",
        "  return (handleLoadToVar(resp), \n",
        "    resp.headers['Cache-Control'] if 'Cache-Control' in resp.headers else None,\n",
        "     resp.headers['Date'] if 'Date' in resp.headers else datetime.datetime.now())"
      ],
      "metadata": {
        "id": "VIGuoCi1X1Sn"
      },
      "id": "VIGuoCi1X1Sn",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "adbf877f-f796-4046-9456-3835db86db70",
      "metadata": {
        "id": "adbf877f-f796-4046-9456-3835db86db70"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "import hashlib\n",
        "\n",
        "class Document:\n",
        "    \n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        \n",
        "    def get(self):\n",
        "        if not self.load():\n",
        "            if not self.download():\n",
        "                raise FileNotFoundError(self.url)\n",
        "            else:\n",
        "                self.persist()\n",
        "    \n",
        "    def download(self):      \n",
        "        #TODO download self.url content, store it in self.content and return True in case of success\n",
        "        try:  \n",
        "          result = wget(self.url)  \n",
        "          if(result is None):\n",
        "            return False\n",
        "          self.content = result\n",
        "          return True\n",
        "        except:\n",
        "          return False\n",
        "    \n",
        "    def persist(self):\n",
        "        filename = hashlib.sha256(self.url.encode()).hexdigest()\n",
        "        with open(filename, \"wb\") as file:\n",
        "          file.write(self.content)\n",
        "            \n",
        "    def load(self):  \n",
        "        #TODO load content from hard drive, store it in self.content and return True in case of success    \n",
        "        try:\n",
        "          filename = hashlib.sha256(self.url.encode()).hexdigest()\n",
        "          with open(filename, \"rb\") as file:\n",
        "            self.content = file.read()\n",
        "          return True\n",
        "        except:\n",
        "          return False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "059d10b7-c8ec-4a31-baff-0f9adaa5ab2d",
      "metadata": {
        "id": "059d10b7-c8ec-4a31-baff-0f9adaa5ab2d"
      },
      "source": [
        "Please study the documentation and implement a descendant to a `Document` class, which will refresh the document in case of expired cache even if the file is already on the hard drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2d3ade05-8bd7-48f4-bfec-0df486aaa1d5",
      "metadata": {
        "id": "2d3ade05-8bd7-48f4-bfec-0df486aaa1d5"
      },
      "outputs": [],
      "source": [
        "class CachedDocument(Document):\n",
        "  \"\"\"\n",
        "    Overloads the document class by storing another file \n",
        "    with .cache extension to store necessary cache information\n",
        "  \"\"\"\n",
        "  def download(self):\n",
        "    try:       \n",
        "      result, cache_data, date = wget_cache(self.url)\n",
        "      if(result is None):\n",
        "        return False\n",
        "      self.content = result\n",
        "      self.cache_data = cache_data\n",
        "      self.fetch_date = date\n",
        "      return True\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      return False\n",
        "\n",
        "  def persist(self):\n",
        "    Document.persist(self)        \n",
        "    cacheFileName = hashlib.sha256(self.url.encode()).hexdigest() + '.cache'\n",
        "    with open(cacheFileName, \"w\") as file:\n",
        "      file.write(f'{self.cache_data},\\n{self.fetch_date}')\n",
        "\n",
        "  def load(self):  \n",
        "    #TODO load content from hard drive, store it in self.content and return True in case of success    \n",
        "    try:\n",
        "      cacheFileName = hashlib.sha256(self.url.encode()).hexdigest() + '.cache'\n",
        "      with open(cacheFileName, \"r\") as file:\n",
        "        self.cache_data = file.readline()\n",
        "        self.fetch_date = file.readline()\n",
        "        if process_cache(self.cache_data, self.fetch_date):\n",
        "          return Document.load(self)\n",
        "        else:\n",
        "          return False\n",
        "      return True\n",
        "    except:\n",
        "      return False          "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a188adbb-f046-46ce-b1c1-8397151d027b",
      "metadata": {
        "id": "a188adbb-f046-46ce-b1c1-8397151d027b"
      },
      "source": [
        "### Tests\n",
        "\n",
        "Add logging to your code and show that your code behaves differently for documents with different caching policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7b917972-084f-43ea-85fd-2a932117ec60",
      "metadata": {
        "id": "7b917972-084f-43ea-85fd-2a932117ec60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249c1207-0efc-4636-ff37-3ef9fc260286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache-header has public\n",
            "Cache hasn't expired \n",
            "Cache-header has public\n",
            "Cache hasn't expired \n",
            "Cache-header has public\n",
            "Cache hasn't expired \n",
            "Cache has expired\n",
            "Fetching file from online\n",
            "Cache has expired\n",
            "Fetching file from online\n",
            "Cache has expired\n",
            "Fetching file from online\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "doc = CachedDocument('https://polyfill.io/v3/polyfill.min.js')\n",
        "doc.get() \n",
        "time.sleep(2)\n",
        "doc.get()\n",
        "time.sleep(2)\n",
        "doc.get()\n",
        "\n",
        "doc = CachedDocument('https://yandex.ru/')\n",
        "doc.get()\n",
        "time.sleep(2)\n",
        "doc.get()\n",
        "time.sleep(2)\n",
        "doc.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c22778c-ccde-42fe-a096-4f1978260e0a",
      "metadata": {
        "id": "3c22778c-ccde-42fe-a096-4f1978260e0a"
      },
      "source": [
        "## 2. [M][35] Languages\n",
        "Maybe you heard, that there are multiple languages in the world. European languages, like Russian and English, use similar puctuation, but even in this family there is ¡Spanish!\n",
        "\n",
        "Other languages can use different punctiation rules, like **Arabic or [Thai](http://www.thai-language.com/ref/breaking-words)**.\n",
        "\n",
        "Your task is to support (at least) three languages (English, Arabic, and Thai) tokenization in your `HtmlDocumentTextData` class descendant.\n",
        "\n",
        "What should you do (acceptance criteria):\n",
        "1. Use any language dection techniques, e.g. [langdetect](https://pypi.org/project/langdetect/).\n",
        "2. Use language-specific tokenization tools, e.g. for [Thai](https://pythainlp.github.io/tutorials/notebooks/pythainlp_get_started.html#Tokenization-and-Segmentation) and [Arabic](https://github.com/CAMeL-Lab/camel_tools).\n",
        "3. Use these pages to test your code: [1](https://www.bangkokair.com/tha/baggage-allowance) and [2](https://alfajr-news.net/details/%D9%85%D8%B4%D8%B1%D9%88%D8%B9-%D8%AF%D9%8A%D9%85%D9%88%D9%82%D8%B1%D8%A7%D8%B7%D9%8A-%D9%81%D9%8A-%D8%A7%D9%84%D9%83%D9%88%D9%86%D8%BA%D8%B1%D8%B3-%D8%A7%D9%84%D8%A3%D9%85%D8%B1%D9%8A%D9%83%D9%8A-%D9%84%D9%85%D8%B9%D8%A7%D9%82%D8%A8%D8%A9-%D8%A8%D9%88%D8%AA%D9%8A%D9%86).\n",
        "4. Pass the tests."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSrIuC1_RjWi",
        "outputId": "4281dcbc-13cd-46ca-9821-c7674f9b058d"
      },
      "id": "GSrIuC1_RjWi",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cc3959e7-7fd3-44e6-9ef5-840001ffdf6e",
      "metadata": {
        "id": "cc3959e7-7fd3-44e6-9ef5-840001ffdf6e"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "import urllib.parse\n",
        "import re\n",
        "\n",
        "class HtmlDocument(CachedDocument):\n",
        "    #TODO extract plain text, images and links from the document    \n",
        "\n",
        "    def parse(self):\n",
        "        def _preprocess_link(link):\n",
        "          \"\"\"\n",
        "            Function for handling relative urls\n",
        "            args:\n",
        "              link: The urls to be processed\n",
        "            response:\n",
        "              The processed urls\n",
        "          \"\"\"\n",
        "          if re.match(\"(?:^[a-z][a-z0-9+\\.-]*:|\\/\\/)\",link ):\n",
        "            return link\n",
        "          else:\n",
        "            return urllib.parse.urljoin(self.url,link)\n",
        "\n",
        "        def _get_anchors(dom):\n",
        "          \"\"\"\n",
        "            Function for getting the urls and the corresponding tags in the dom\n",
        "            args:\n",
        "              dom: The dom \n",
        "            response:\n",
        "              A list of all anchor links and names              \n",
        "          \"\"\"\n",
        "          all_hrefs = dom.find_all('a', href=True)\n",
        "          all_urls = set()\n",
        "          return list(set((a.text,_preprocess_link(a['href'])) for a in all_hrefs))\n",
        "        \n",
        "        def _get_images(dom):\n",
        "          \"\"\"\n",
        "            Function for getting the urls and the corresponding tags in the dom\n",
        "            args:\n",
        "              dom: The dom \n",
        "            response:\n",
        "              A list of all the image sources              \n",
        "          \"\"\"          \n",
        "          all_images= dom.find_all('img', src=True)\n",
        "          all_src = set()          \n",
        "          return list(set([_preprocess_link(img['src']) for img in all_images]))                  \n",
        "        \n",
        "        def tag_visible(element):\n",
        "          \"\"\"\n",
        "            Function for checking if a html element is among the visible elements in the dom\n",
        "            args:\n",
        "              element: The HTML element to be checked\n",
        "            response: A boolean specifying if an element is visible                                            \n",
        "          \"\"\"\n",
        "          if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
        "              return False\n",
        "          if isinstance(element, Comment):\n",
        "              return False\n",
        "          return True\n",
        "        \n",
        "        def _get_text(dom):\n",
        "          \"\"\"\n",
        "            Function for getting visible texts in the dom\n",
        "            args:\n",
        "              dom: The dom \n",
        "            response: A string of all the visible texts             \n",
        "          \"\"\"\n",
        "          texts = dom.findAll(text=True)\n",
        "          visible_texts = filter(tag_visible, texts)\n",
        "          return u\" \".join(t.strip() for t in visible_texts)\n",
        "        \n",
        "        try:\n",
        "          dom = BeautifulSoup(self.content.decode())  \n",
        "          self.anchors = _get_anchors(dom)\n",
        "          self.images = _get_images(dom)\n",
        "          self.text = _get_text(dom)\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from nltk import tokenize\n",
        "\n",
        "class HtmlDocumentTextData:\n",
        "    \n",
        "    def __init__(self, url):\n",
        "        self.doc = HtmlDocument(url)\n",
        "        try:\n",
        "          self.doc.get()\n",
        "          self.doc.parse()\n",
        "        except FileNotFoundError:\n",
        "          print(\"File Not Found\")\n",
        "    \n",
        "    def get_sentences(self):\n",
        "        #TODO implement sentence parser\n",
        "        result = nltk.sent_tokenize(self.doc.text.strip())\n",
        "        return result\n",
        "    \n",
        "    def get_word_stats(self):\n",
        "        result = nltk.word_tokenize(self.doc.text.strip())\n",
        "        #TODO return Counter object of the document, containing mapping {`word` -> count_in_doc}\n",
        "        return Counter(map(str.lower,result))"
      ],
      "metadata": {
        "id": "Oj2JNbvPZHKp"
      },
      "id": "Oj2JNbvPZHKp",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_65RuZcPlZ5Z",
        "outputId": "721d7ad7-1246-4741-dfa6-c39de0403b31"
      },
      "id": "_65RuZcPlZ5Z",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.8/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from langdetect) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pythainlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB1re69InI37",
        "outputId": "d610e900-58d8-4d15-b4fb-c44b342a8cae"
      },
      "id": "AB1re69InI37",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.8/dist-packages (3.1.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from pythainlp) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install camel-tools\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyD5NSlXpJiB",
        "outputId": "3738c2bb-e7f8-4891-a98e-091e82ed6879"
      },
      "id": "QyD5NSlXpJiB",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: camel-tools in /usr/local/lib/python3.8/dist-packages (1.4.1)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.8/dist-packages (from camel-tools) (0.5.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from camel-tools) (0.3.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from camel-tools) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from camel-tools) (1.0.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from camel-tools) (0.8.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from camel-tools) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from camel-tools) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from camel-tools) (1.3.5)\n",
            "Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from camel-tools) (4.26.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from camel-tools) (2.25.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.8/dist-packages (from camel-tools) (5.3.0)\n",
            "Requirement already satisfied: camel-kenlm in /usr/local/lib/python3.8/dist-packages (from camel-tools) (2021.12.27)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.8/dist-packages (from camel-tools) (2.2.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.8/dist-packages (from camel-tools) (0.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from camel-tools) (1.21.6)\n",
            "Requirement already satisfied: pyrsistent in /usr/local/lib/python3.8/dist-packages (from camel-tools) (0.19.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.8/dist-packages (from camel-tools) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from camel-tools) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3->camel-tools) (4.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.2->camel-tools) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.2->camel-tools) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.2->camel-tools) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.2->camel-tools) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.2->camel-tools) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.2->camel-tools) (0.12.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->camel-tools) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->camel-tools) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->camel-tools) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->camel-tools) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->camel-tools) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->camel-tools) (4.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->camel-tools) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->camel-tools) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e829ea49-b334-41bf-9a6d-32cd1f046e61",
      "metadata": {
        "id": "e829ea49-b334-41bf-9a6d-32cd1f046e61"
      },
      "outputs": [],
      "source": [
        "from langdetect import detect\n",
        "from pythainlp import word_tokenize\n",
        "from camel_tools.tokenizers.word import simple_word_tokenize\n",
        "\n",
        "class MultilingualHtmlDocumentTextData(HtmlDocumentTextData):\n",
        "  def get_word_stats(self):\n",
        "        lang = detect(self.doc.text.strip())\n",
        "        if lang == 'th':\n",
        "          result = word_tokenize(self.doc.text.strip(), keep_whitespace=False)\n",
        "        elif lang == 'ar':\n",
        "          result = simple_word_tokenize(self.doc.text.strip())\n",
        "        else:\n",
        "          result = nltk.word_tokenize(self.doc.text.strip())\n",
        "        #TODO return Counter object of the document, containing mapping {`word` -> count_in_doc}\n",
        "        return Counter(map(str.lower,result))\n",
        "    #TODO your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4878c7fe-727d-4f6e-a49a-ff5e79093d89",
      "metadata": {
        "id": "4878c7fe-727d-4f6e-a49a-ff5e79093d89"
      },
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dc116243-9e82-4de5-8167-be862740e976",
      "metadata": {
        "id": "dc116243-9e82-4de5-8167-be862740e976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873657f0-0f78-480d-9bcd-91c85a80a983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache has no-store or no-cache field\n",
            "Fetching file from online\n",
            "[('สัมภาระ', 34), ('เรา', 24), ('การ', 23), ('ที่', 21), ('กิโลกรัม', 21), ('ของ', 20), ('และ', 20), ('เดินทาง', 17), ('เที่ยวบิน', 16), ('บริการ', 16)]\n",
            "Cache has expired\n",
            "Fetching file from online\n",
            "[('.', 7), (':', 6), ('-', 5), ('أخبار', 5), ('الفجر', 5), ('فن', 4), ('الأكثر', 4), ('قراءة', 4), ('أخترنا', 4), ('لك', 4)]\n"
          ]
        }
      ],
      "source": [
        "doc = MultilingualHtmlDocumentTextData(\"https://www.bangkokair.com/tha/baggage-allowance\")\n",
        "print(doc.get_word_stats().most_common(10))\n",
        "\n",
        "doc = MultilingualHtmlDocumentTextData(\"https://alfajr-news.net/details/%D9%85%D8%B4%D8%B1%D9%88%D8%B9-%D8%AF%D9%8A%D9%85%D9%88%D9%82%D8%B1%D8%A7%D8%B7%D9%8A-%D9%81%D9%8A-%D8%A7%D9%84%D9%83%D9%88%D9%86%D8%BA%D8%B1%D8%B3-%D8%A7%D9%84%D8%A3%D9%85%D8%B1%D9%8A%D9%83%D9%8A-%D9%84%D9%85%D8%B9%D8%A7%D9%82\")\n",
        "print(doc.get_word_stats().most_common(10))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai",
      "language": "python",
      "name": "ai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}